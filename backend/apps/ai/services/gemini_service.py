# backend/ai_services/gemini_service.py
import google.generativeai as genai
from django.conf import settings
from typing import List, Dict, Optional
import json
import logging

logger = logging.getLogger(__name__)

class GeminiAIService:
    """Service d'IA utilisant l'API Gemini gratuite pour OpportuCI"""
    
    def __init__(self):
        genai.configure(api_key=settings.GEMINI_API_KEY)
        self.model = genai.GenerativeModel('gemini-pro')
    
    def get_opportunity_recommendations(self, user_profile: Dict, opportunities: List[Dict], limit: int = 5) -> List[Dict]:
        """
        Recommande des opportunit√©s bas√©es sur le profil utilisateur
        Utilise Gemini pour analyser la compatibilit√©
        """
        try:
            # Pr√©parer le prompt avec les donn√©es utilisateur
            user_context = self._format_user_profile(user_profile)
            opportunities_context = self._format_opportunities(opportunities[:20])  # Limite pour √©viter de d√©passer les tokens
            
            prompt = f"""
            En tant qu'expert en orientation professionnelle pour jeunes ivoiriens, analysez ce profil utilisateur et recommandez les {limit} meilleures opportunit√©s parmi celles disponibles.

            PROFIL UTILISATEUR:
            {user_context}

            OPPORTUNIT√âS DISPONIBLES:
            {opportunities_context}

            Retournez uniquement un JSON avec cette structure (pas de texte avant/apr√®s):
            {{
                "recommendations": [
                    {{
                        "opportunity_id": "id",
                        "match_score": 0.85,
                        "match_reason": "Raison de la compatibilit√© en fran√ßais",
                        "key_advantages": ["avantage1", "avantage2"]
                    }}
                ]
            }}
            
            Crit√®res de matching:
            - Comp√©tences requises vs acquises
            - Niveau d'√©ducation
            - Centres d'int√©r√™t
            - Localisation
            - Opportunit√©s de d√©veloppement
            """
            
            response = self.model.generate_content(prompt)
            
            # Parser la r√©ponse JSON
            try:
                result = json.loads(response.text.strip())
                return result.get('recommendations', [])
            except json.JSONDecodeError:
                logger.error(f"Erreur parsing JSON: {response.text}")
                return []
                
        except Exception as e:
            logger.error(f"Erreur Gemini recommendations: {str(e)}")
            return []
    
    def generate_career_advice(self, user_profile: Dict, career_goals: str = "") -> Dict:
        """G√©n√®re des conseils de carri√®re personnalis√©s"""
        try:
            user_context = self._format_user_profile(user_profile)
            
            prompt = f"""
            En tant que conseiller en carri√®re sp√©cialis√© dans le march√© du travail ivoirien et africain, analysez ce profil et donnez des conseils personnalis√©s.

            PROFIL:
            {user_context}
            
            OBJECTIFS DE CARRI√àRE: {career_goals or "Non sp√©cifi√©s"}

            Retournez uniquement un JSON avec cette structure:
            {{
                "career_assessment": {{
                    "strengths": ["force1", "force2", "force3"],
                    "areas_to_improve": ["am√©lioration1", "am√©lioration2"],
                    "market_opportunities": ["opportunit√©1", "opportunit√©2"],
                    "recommended_skills": ["comp√©tence1", "comp√©tence2", "comp√©tence3"],
                    "next_steps": ["√©tape1", "√©tape2", "√©tape3"],
                    "salary_estimation": "Estimation en FCFA pour la C√¥te d'Ivoire",
                    "career_path_suggestions": ["voie1", "voie2"]
                }}
            }}
            
            Contexte important: March√© du travail ivoirien/africain, secteurs en croissance (tech, agribusiness, finance), d√©fis locaux.
            """
            
            response = self.model.generate_content(prompt)
            
            try:
                result = json.loads(response.text.strip())
                return result.get('career_assessment', {})
            except json.JSONDecodeError:
                logger.error(f"Erreur parsing career advice: {response.text}")
                return {}
                
        except Exception as e:
            logger.error(f"Erreur Gemini career advice: {str(e)}")
            return {}
    
    def analyze_skill_gaps(self, user_skills: List[str], target_position: str) -> Dict:
        """Analyse les gaps de comp√©tences pour un poste cible"""
        try:
            prompt = f"""
            Analysez les comp√©tences actuelles d'un utilisateur par rapport √† un poste cible sur le march√© ivoirien.

            COMP√âTENCES ACTUELLES: {', '.join(user_skills)}
            POSTE VIS√â: {target_position}

            Retournez uniquement un JSON:
            {{
                "skill_analysis": {{
                    "matching_skills": ["comp√©tence correspondante1", "comp√©tence correspondante2"],
                    "missing_critical_skills": ["comp√©tence critique manquante1", "comp√©tence critique manquante2"],
                    "nice_to_have_skills": ["comp√©tence bonus1", "comp√©tence bonus2"],
                    "learning_priority": ["priorit√©1", "priorit√©2", "priorit√©3"],
                    "estimated_learning_time": "X mois",
                    "recommended_resources": [
                        {{"skill": "comp√©tence", "resource": "ressource recommand√©e", "type": "cours/certification/pratique"}}
                    ]
                }}
            }}
            
            Contexte: March√© du travail ivoirien, ressources disponibles localement.
            """
            
            response = self.model.generate_content(prompt)
            
            try:
                result = json.loads(response.text.strip())
                return result.get('skill_analysis', {})
            except json.JSONDecodeError:
                return {}
                
        except Exception as e:
            logger.error(f"Erreur skill gaps analysis: {str(e)}")
            return {}
    
    def generate_interview_prep(self, opportunity: Dict, user_profile: Dict) -> Dict:
        """G√©n√®re une pr√©paration d'entretien personnalis√©e"""
        try:
            user_context = self._format_user_profile(user_profile)
            
            prompt = f"""
            Pr√©parez un guide d'entretien personnalis√© pour cette opportunit√©.

            OPPORTUNIT√â:
            - Titre: {opportunity.get('title', '')}
            - Organisation: {opportunity.get('organization', '')}
            - Description: {opportunity.get('description', '')[:500]}
            - Secteur: {opportunity.get('category', '')}

            PROFIL CANDIDAT:
            {user_context}

            Retournez uniquement un JSON:
            {{
                "interview_prep": {{
                    "likely_questions": [
                        {{"question": "Question probable", "suggested_answer_points": ["point1", "point2"], "why_this_question": "Explication"}}
                    ],
                    "key_strengths_to_highlight": ["force √† mettre en avant1", "force √† mettre en avant2"],
                    "potential_concerns_to_address": ["pr√©occupation potentielle1"],
                    "questions_to_ask_interviewer": ["question1", "question2", "question3"],
                    "company_research_points": ["point recherche1", "point recherche2"],
                    "dress_code_suggestion": "Code vestimentaire recommand√©",
                    "cultural_tips": "Conseils culturels pour le contexte ivoirien/africain"
                }}
            }}
            """
            
            response = self.model.generate_content(prompt)
            
            try:
                result = json.loads(response.text.strip())
                return result.get('interview_prep', {})
            except json.JSONDecodeError:
                return {}
                
        except Exception as e:
            logger.error(f"Erreur interview prep: {str(e)}")
            return {}
    
    def _format_user_profile(self, profile: Dict) -> str:
        """Formate le profil utilisateur pour les prompts"""
        return f"""
        - Nom: {profile.get('name', 'Non sp√©cifi√©')}
        - Niveau d'√©ducation: {profile.get('education_level', 'Non sp√©cifi√©')}
        - Institution: {profile.get('institution', 'Non sp√©cifi√©')}
        - Comp√©tences: {', '.join(profile.get('skills', []))}
        - Centres d'int√©r√™t: {', '.join(profile.get('interests', []))}
        - Localisation: {profile.get('location', 'C√¥te d\'Ivoire')}
        - Exp√©rience: {profile.get('experience', 'D√©butant')}
        - Objectifs: {profile.get('career_goals', 'En d√©finition')}
        """
    
    def _format_opportunities(self, opportunities: List[Dict]) -> str:
        """Formate la liste d'opportunit√©s pour les prompts"""
        formatted = []
        for i, opp in enumerate(opportunities, 1):
            formatted.append(f"""
            {i}. ID: {opp.get('id')} | Titre: {opp.get('title', '')} | 
            Organisation: {opp.get('organization', '')} | 
            Cat√©gorie: {opp.get('category', '')} | 
            Lieu: {opp.get('location', '')} | 
            Niveau: {opp.get('education_level', 'Tous niveaux')} | 
            Description: {opp.get('description', '')[:200]}...
            """)
        return '\n'.join(formatted)
# Ajouter √† la fin de la classe GeminiAIService dans gemini_service.py

    def generate_interview_response(
        self,
        conversation: list,
        company_context: dict,
        interview_type: str
    ) -> str:
        """
        G√©n√®re la r√©ponse du recruteur IA pendant l'entretien
        
        Args:
            conversation: Historique complet de la conversation
            company_context: Contexte de l'entreprise
            interview_type: Type d'entretien (behavioral, technical, etc.)
        
        Returns:
            Message du recruteur
        """
        # Formater l'historique
        formatted_history = self._format_conversation(conversation)
        
        # D√©terminer le nombre de questions pos√©es
        recruiter_messages = [m for m in conversation if m['role'] == 'recruiter']
        question_count = len(recruiter_messages) - 1  # -1 pour le message d'ouverture
        
        # Adapter le prompt selon le type d'entretien
        interview_prompts = {
            'behavioral': "Pose des questions sur l'exp√©rience pass√©e, les soft skills, la gestion de situations",
            'technical': "Pose des questions techniques sur les comp√©tences requises pour le poste",
            'phone': "Garde un ton l√©ger, pose des questions g√©n√©rales de pr√©s√©lection",
            'panel': "Simule plusieurs recruteurs avec des angles diff√©rents"
        }
        
        prompt = f"""
        Tu es {company_context['recruiter_name']}, {company_context['recruiter_role']} chez {company_context['company_name']}.
        Tu m√®nes un entretien {interview_type} pour le poste de {company_context['position']}.
        
        CONTEXTE:
        - Entreprise ivoirienne, culture professionnelle mais bienveillante
        - Dur√©e pr√©vue : ~15 minutes
        - Tu as d√©j√† pos√© {question_count} questions
        
        INSTRUCTIONS:
        - {interview_prompts.get(interview_type, 'Pose des questions pertinentes')}
        - Reste naturel et professionnel
        - Valorise les bonnes r√©ponses avec des encouragements
        - Si r√©ponse faible, aide avec des indices sans √™tre condescendant
        - Apr√®s 5-6 questions, commence √† conclure l'entretien
        - Si question_count >= 6, termine l'entretien avec remerciements et prochaines √©tapes
        
        HISTORIQUE CONVERSATION:
        {formatted_history}
        
        G√©n√®re la PROCHAINE question ou remarque du recruteur (1-2 phrases max).
        Si c'est la fin, remercie le candidat et explique la suite.
        """
        
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©ponse interview: {e}")
            # Fallback
            if question_count >= 6:
                return "Merci beaucoup pour vos r√©ponses. Nous avons termin√© cet entretien. Nous reviendrons vers vous dans les prochains jours concernant la suite du processus. Bonne journ√©e !"
            return "Je vois. Pouvez-vous m'en dire un peu plus sur votre motivation pour ce poste ?"
    
    def evaluate_interview(
        self,
        conversation: list,
        opportunity,
        interview_type: str
    ) -> dict:
        """
        √âvalue la performance d'entretien avec scoring d√©taill√©
        
        Args:
            conversation: Historique complet
            opportunity: Opportunit√© vis√©e
            interview_type: Type d'entretien
            
        Returns:
            Dict avec scores, feedback, recommandations
        """
        formatted_history = self._format_conversation(conversation)
        
        prompt = f"""
        √âvalue cette simulation d'entretien d'embauche en tant que recruteur professionnel.
        
        POSTE: {opportunity.title} chez {opportunity.organization}
        TYPE: {interview_type}
        SECTEUR: {opportunity.category.name if hasattr(opportunity, 'category') and opportunity.category else 'G√©n√©ral'}
        
        TRANSCRIPT COMPLET:
        {formatted_history}
        
        Fournis une √©valuation d√©taill√©e en JSON strict (pas de markdown):
        {{
            "overall_score": 75,
            "detailed_scores": {{
                "communication": 80,
                "technical_knowledge": 70,
                "motivation": 85,
                "problem_solving": 65,
                "cultural_fit": 75
            }},
            "strengths": [
                "Point fort 1 avec exemple pr√©cis",
                "Point fort 2",
                "Point fort 3"
            ],
            "improvements": [
                "Am√©lioration 1 avec suggestion concr√®te",
                "Am√©lioration 2",
                "Am√©lioration 3"
            ],
            "standout_moments": [
                "Moment particuli√®rement bon"
            ],
            "red_flags": [
                "Points d'attention √©ventuels"
            ],
            "feedback": "Feedback g√©n√©ral constructif et encourageant (3-4 phrases)",
            "hiring_recommendation": "hire|maybe|no_hire",
            "recommended_practice": [
                "Exercice pratique 1 pour progresser",
                "Exercice pratique 2"
            ]
        }}
        
        Contexte : Jeune ivoirien en d√©but de carri√®re, sois juste mais encourageant.
        """
        
        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text.strip())
            return result
        except Exception as e:
            logger.error(f"Erreur √©valuation interview: {e}")
            # Fallback scores neutres
            return {
                "overall_score": 60,
                "detailed_scores": {
                    "communication": 60,
                    "technical_knowledge": 60,
                    "motivation": 60,
                    "problem_solving": 60,
                    "cultural_fit": 60
                },
                "strengths": ["Participation √† la simulation"],
                "improvements": ["Continuer √† pratiquer les entretiens"],
                "feedback": "Merci d'avoir compl√©t√© cette simulation. Continue de t'entra√Æner !",
                "hiring_recommendation": "maybe",
                "recommended_practice": ["Pratiquer les r√©ponses aux questions comportementales"]
            }
    
    def generate_personalized_help(
        self,
        module,
        user_progress,
        struggles: list
    ) -> str:
        """
        G√©n√®re de l'aide personnalis√©e quand utilisateur a des difficult√©s
        
        Args:
            module: Module d'apprentissage
            user_progress: Progression utilisateur
            struggles: Liste des points de difficult√© d√©tect√©s
            
        Returns:
            Message d'aide personnalis√©
        """
        prompt = f"""
        Un utilisateur rencontre des difficult√©s sur ce module d'apprentissage.
        
        MODULE: {module.title}
        COMP√âTENCE: {module.skill_taught}
        NIVEAU: {module.get_difficulty_level_display()}
        
        PROGRESSION:
        - Tentatives: {user_progress.attempts}
        - Meilleur score: {user_progress.best_score or 0}%
        - Temps pass√©: {user_progress.time_spent_minutes} minutes
        
        DIFFICULT√âS D√âTECT√âES: {struggles if struggles else "Scores faibles r√©p√©t√©s"}
        
        G√©n√®re des conseils personnalis√©s en fran√ßais (3-4 paragraphes):
        1. **Diagnostic**: Identifie le probl√®me probable
        2. **Conseils pratiques**: 3 conseils sp√©cifiques et actionnables
        3. **Ressources**: Suggestions de pratique ou r√©vision
        4. **Encouragement**: Message motivant adapt√© au contexte ivoirien
        
        Ton: Bienveillant, mentor proche, pas condescendant.
        """
        
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration aide: {e}")
            return "Continue de pratiquer ! Chaque tentative te rapproche du succ√®s. N'h√©site pas √† revoir les concepts de base avant de r√©essayer. Tu peux le faire ! üí™"
    
    def generate_learning_path(self, context: dict) -> dict:
        """
        G√©n√®re un parcours d'apprentissage optimal avec IA
        
        Args:
            context: Dict avec user_profile, opportunity, skill_gaps
            
        Returns:
            Dict avec modules, dur√©e estim√©e, conseils
        """
        user_profile = context.get('user_profile', {})
        opportunity = context.get('opportunity', {})
        skill_gaps = context.get('skill_gaps', [])
        
        # Formater les gaps
        gaps_text = "\n".join([
            f"- {gap['skill']}: Gap de {int(gap['gap']*100)}% (Priorit√©: {gap['priority']})"
            for gap in skill_gaps[:10]  # Top 10
        ])
        
        prompt = f"""
        Cr√©e un parcours d'apprentissage optimal pour ce profil.
        
        UTILISATEUR:
        - Nom: {user_profile.get('name', 'Utilisateur')}
        - Niveau: {user_profile.get('education_level', 'D√©butant')}
        - Comp√©tences actuelles: {', '.join(list(user_profile.get('current_skills', {}).keys())[:5])}
        
        OPPORTUNIT√â VIS√âE:
        - Poste: {opportunity.get('title', 'Non sp√©cifi√©')}
        - Entreprise: {opportunity.get('organization', 'Non sp√©cifi√©')}
        - Type: {opportunity.get('type', 'Non sp√©cifi√©')}
        
        GAPS DE COMP√âTENCES IDENTIFI√âS:
        {gaps_text}
        
        CONTRAINTES:
        - Parcours max 40 heures (utilisateur a vie active)
        - Priorit√© aux comp√©tences critiques
        - Contenus adapt√©s au contexte ivoirien
        - Mix th√©orie/pratique 30/70
        
        G√©n√®re un parcours en JSON strict:
        {{
            "modules": [
                {{
                    "skill": "Python basics",
                    "type": "video",
                    "duration_minutes": 30,
                    "priority": "critical",
                    "title": "Titre attractif en fran√ßais",
                    "description": "Description courte",
                    "learning_objectives": ["obj1", "obj2", "obj3"],
                    "practical_project": "Projet concret ivoirien"
                }}
            ],
            "estimated_total_hours": 25,
            "recommended_pace": "2h par jour pendant 2 semaines",
            "success_tips": ["tip1", "tip2", "tip3"],
            "milestone_rewards": ["reward1", "reward2"]
        }}
        
        G√©n√®re entre 8 et 15 modules selon la complexit√©.
        """
        
        try:
            response = self.model.generate_content(prompt)
            result = json.loads(response.text.strip())
            return result
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration parcours: {e}")
            # Fallback basique
            return {
                "modules": [
                    {
                        "skill": skill_gaps[0]['skill'] if skill_gaps else "Comp√©tence de base",
                        "type": "video",
                        "duration_minutes": 15,
                        "priority": "high",
                        "title": f"Introduction √† {skill_gaps[0]['skill'] if skill_gaps else 'la comp√©tence'}",
                        "description": "Module d'introduction",
                        "learning_objectives": ["Comprendre les bases"],
                        "practical_project": "Exercice pratique"
                    }
                ],
                "estimated_total_hours": 10,
                "recommended_pace": "1h par jour",
                "success_tips": ["Pratique r√©guli√®re", "Ne pas h√©siter √† poser des questions"],
                "milestone_rewards": ["Progression constante"]
            }
    
    def _format_conversation(self, conversation: list) -> str:
        """
        Formate l'historique de conversation pour les prompts
        
        Args:
            conversation: Liste de messages {role, message, timestamp}
            
        Returns:
            String format√©
        """
        formatted = []
        for msg in conversation:
            role_label = "Recruteur" if msg['role'] == 'recruiter' else "Candidat"
            formatted.append(f"{role_label}: {msg['message']}")
        
        return "\n".join(formatted)